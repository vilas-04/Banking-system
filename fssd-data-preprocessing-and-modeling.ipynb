{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11436792,"sourceType":"datasetVersion","datasetId":7163783},{"sourceId":11475552,"sourceType":"datasetVersion","datasetId":7192079},{"sourceId":11477730,"sourceType":"datasetVersion","datasetId":7193671},{"sourceId":11478329,"sourceType":"datasetVersion","datasetId":7194089},{"sourceId":11478354,"sourceType":"datasetVersion","datasetId":7194106},{"sourceId":11481044,"sourceType":"datasetVersion","datasetId":7195886},{"sourceId":11481075,"sourceType":"datasetVersion","datasetId":7195904}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/farming-dataset/farming_decision_support_extended_dataset.csv')\ndf.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.tail()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.describe","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Check null values\nprint(\"Print null values :/n\",df.isnull().sum())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Handle null values\nfor col in df.columns:\n    if df[col].dtype == 'object':\n        df[col].fillna(df[col].mode()[0], inplace=True)\n    else:\n        df[col].fillna(df[col].mean(), inplace=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Print null values :/n\",df.isnull().sum())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Drop duplicates\ndf.drop_duplicates(inplace=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Encode categorical columns\ndf = pd.get_dummies(df, drop_first=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Standardize numeric features\nscaler = StandardScaler()\nnumeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\ndf[numeric_cols] = scaler.fit_transform(df[numeric_cols])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Train-test split\nX = df.drop(columns=df.columns[-1])  # Assume last column is the target\ny = df[df.columns[-1]]               # Adjust this if your target column is known\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Data Visualization","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Bar Plot (for target distribution if categorical)\nif y.nunique() < 20:\n    plt.figure(figsize=(6, 4))\n    sns.countplot(x=y)\n    plt.title(\"Target Variable - Bar Plot\")\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Box Plot (for numeric features)\nplt.figure(figsize=(12, 6))\nsns.boxplot(data=df[numeric_cols])\nplt.xticks(rotation=45)\nplt.title(\"Box Plot for Numeric Features\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Distribution Plot (histogram + KDE for a sample feature)\n # Choose the first numeric column\nsample_feature = numeric_cols[0]\nplt.figure(figsize=(6, 4))\nsns.histplot(df[sample_feature], kde=True, bins=30)\nplt.title(f\"Distribution of '{sample_feature}'\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#ALGORITHMS","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report,accuracy_score,confusion_matrix,mean_squared_error\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom sklearn.linear_model import LinearRegression","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Encode categorical variables\nfor col in df.select_dtypes(include='object'):\n    df[col] = LabelEncoder().fit_transform(df[col])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#ML MODELS","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Decision tree\ndt = DecisionTreeClassifier()\ndt.fit(X_train, y_train)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = dt.predict(X_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"accuracy = accuracy_score(y_test, y_pred)*100\nprint(f\"Accuracy Score: {accuracy:.2f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":" # Confusion Matrix\ncm = confusion_matrix(y_test, y_pred)\n    \n# Plot confusion matrix with seaborn\nplt.figure(figsize=(6, 5))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title(f'Confusion Matrix')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Support Vector Machine\nsvm = SVC()\nsvm.fit(X_train, y_train)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = svm.predict(X_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"accuracy = accuracy_score(y_test, y_pred)*100\nprint(f\"Accuracy Score: {accuracy:.2f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":" # Confusion Matrix\ncm = confusion_matrix(y_test, y_pred)\n    \n# Plot confusion matrix with seaborn\nplt.figure(figsize=(6, 5))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title(f'Confusion Matrix')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Random Forest\nrf=RandomForestClassifier()\nrf.fit(X_train, y_train)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = rf.predict(X_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"accuracy = accuracy_score(y_test, y_pred)*100\nprint(f\"Accuracy Score: {accuracy:.2f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":" # Confusion Matrix\ncm = confusion_matrix(y_test, y_pred)\n    \n# Plot confusion matrix with seaborn\nplt.figure(figsize=(6, 5))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title(f'Confusion Matrix')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Regression","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lr = LinearRegression()\nlr.fit(X_train, y_train)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = lr.predict(X_test)\nprint(\"MSE:\", mean_squared_error(y_test, y_pred))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"rf = RandomForestRegressor()\nrf.fit(X_train, y_train)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = rf.predict(X_test)\nprint(\"MSE:\", mean_squared_error(y_test, y_pred))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Deep Learning algorithm","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#crop image dataset","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"TensorFlow version:\", tf.__version__)\nprint(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Dataset path\ncrop_image = \"/kaggle/input/images-of-crop\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Image Parameters\nIMAGE_SIZE = (224, 224)\nBATCH_SIZE = 32","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Data Generators\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    validation_split=0.2\n)\n\ntrain_data = train_datagen.flow_from_directory(\n  crop_image,\n    target_size=IMAGE_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    subset='training'\n)\n\nval_data = train_datagen.flow_from_directory(\n    crop_image,\n    target_size=IMAGE_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    subset='validation'\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Take one batch from the generator\nimage_batch, label_batch = next(train_data)\n\n# Decode labels from one-hot to class index\nlabels = tf.argmax(label_batch, axis=1)\n\n# Get class names from the generator\nclass_names = list(train_data.class_indices.keys())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10, 10))\nfor i in range(16):\n    plt.subplot(4, 4, i + 1)\n    img = image_batch[i]\n    label = labels[i].numpy()\n    plt.imshow(img)  # images are already scaled RGB\n    plt.title(f'Label: {class_names[label]}')\n    plt.axis('off')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CNN Model\nmodel = Sequential([\n    Conv2D(32, (3, 3), activation='relu', input_shape=IMAGE_SIZE + (3,)),\n    MaxPooling2D(),\n    Conv2D(64, (3, 3), activation='relu'),\n    MaxPooling2D(),\n    Conv2D(128, (3, 3), activation='relu'),\n    MaxPooling2D(),\n    Flatten(),\n    Dense(128, activation='relu'),\n    Dropout(0.5),\n    Dense(train_data.num_classes, activation='softmax')\n])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ⚙️ Compile\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = model.fit(\n    train_data,  # Using the training data generator\n    validation_data=val_data,  # Using the validation data generator\n    epochs=6\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Model Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Save model\nmodel.save('crop_image_cnn_model.h5')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Agricultural crop  image dataset","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"agricultural_crops = \"/kaggle/input/agricultural-crops\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"IMAGE_SIZE = (180, 180)\nBATCH_SIZE = 32","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"datagen = ImageDataGenerator(\n    rescale=1./255,\n    validation_split=0.2\n)\n\ntrain_data = datagen.flow_from_directory(\n    agricultural_crops,\n    target_size=IMAGE_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    subset='training'\n)\n\nval_data = datagen.flow_from_directory(\n   agricultural_crops,\n    target_size=IMAGE_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    subset='validation'\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\n# Get class indices and reverse map to class names\nclass_names = list(train_data.class_indices.keys())\n\n# Get one batch of images and labels\nimages, labels = next(train_data)\n\n# Plot 16 images\nplt.figure(figsize=(10, 10))\nfor i in range(16):\n    plt.subplot(4, 4, i + 1)\n    plt.imshow(images[i])\n    label_index = np.argmax(labels[i])  # Get index of the class\n    plt.title(f\"{class_names[label_index]}\")\n    plt.axis(\"off\")\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CNN Model\nmodel = Sequential([\n    Conv2D(32, (3, 3), activation='relu', input_shape=IMAGE_SIZE + (3,)),\n    MaxPooling2D(),\n    Conv2D(64, (3, 3), activation='relu'),\n    MaxPooling2D(),\n    Conv2D(128, (3, 3), activation='relu'),\n    MaxPooling2D(),\n    Flatten(),\n    Dense(128, activation='relu'),\n    Dropout(0.5),\n    Dense(train_data.num_classes, activation='softmax')\n])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train\nhistory = model.fit(\n    train_data,\n    validation_data=val_data,\n    epochs=4\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Val Accuracy')\nplt.title(\"Model Accuracy\")\nplt.legend()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save(\"agricultural_crop_classifier.h5\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Soil type dataset","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"soil_type = '/kaggle/input/type-of-soil'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"IMAGE_SIZE = (224, 224)\nBATCH_SIZE = 32","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Data Generator\ndatagen = ImageDataGenerator(\n    rescale=1./255,\n    validation_split=0.2\n)\n\n# Load Training Data\ntrain_data = datagen.flow_from_directory(\n    soil_type,\n    target_size=IMAGE_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    subset='training'\n)\n\n#Load Validation Data\nval_data = datagen.flow_from_directory(\n    soil_type,\n    target_size=IMAGE_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    subset='validation'\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"images, labels = next(train_data)\n\n# 🏷️ Get class names from the generator\nclass_names = list(train_data.class_indices.keys())\n\n# Plot 16 sample images\nplt.figure(figsize=(10, 10))\nfor i in range(16):\n    plt.subplot(4, 4, i + 1)\n    plt.imshow(images[i])\n    label_index = np.argmax(labels[i])  # Convert one-hot to class index\n    plt.title(f\"{class_names[label_index]}\")\n    plt.axis(\"off\")\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = Sequential([\n    Conv2D(32, (3, 3), activation='relu', input_shape=IMAGE_SIZE + (3,)),\n    MaxPooling2D(),\n    Conv2D(64, (3, 3), activation='relu'),\n    MaxPooling2D(),\n    Conv2D(128, (3, 3), activation='relu'),\n    MaxPooling2D(),\n    Flatten(),\n    Dense(128, activation='relu'),\n    Dropout(0.5),\n    Dense(train_data.num_classes, activation='softmax')\n])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = model.fit(\n    train_data,\n    validation_data=val_data,\n    epochs=5\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Val Accuracy')\nplt.title(\"Soil Type Classifier Accuracy\")\nplt.legend()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save(\"soil_type_classifier_model.h5\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Vegetable dataset","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"vegetable_image = '/kaggle/input/vegetable-image'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"IMAGE_SIZE = (224, 224)\nBATCH_SIZE = 32","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Data Generator with Rescaling + Validation Split\ndatagen = ImageDataGenerator(\n    rescale=1./255,\n    validation_split=0.2\n)\n\n# Load Training Data\ntrain_data = datagen.flow_from_directory(\n    vegetable_image,\n    target_size=IMAGE_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    subset='training'\n)\n# Load Validation Data\nval_data = datagen.flow_from_directory(\n    vegetable_image,\n    target_size=IMAGE_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    subset='validation'\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class_names = list(train_data.class_indices.keys())\n\n# Get one batch of images and labels\nimages, labels = next(train_data)\n\n# Plot 16 vegetable images\nplt.figure(figsize=(10, 10))\nfor i in range(16):\n    plt.subplot(4, 4, i + 1)\n    plt.imshow(images[i])\n    label_index = np.argmax(labels[i])\n    plt.title(f\"{class_names[label_index]}\")\n    plt.axis(\"off\")\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = Sequential([\n    Conv2D(32, (3, 3), activation='relu', input_shape=IMAGE_SIZE + (3,)),\n    MaxPooling2D(),\n    Conv2D(64, (3, 3), activation='relu'),\n    MaxPooling2D(),\n    Conv2D(128, (3, 3), activation='relu'),\n    MaxPooling2D(),\n    Flatten(),\n    Dense(128, activation='relu'),\n    Dropout(0.5),\n    Dense(train_data.num_classes, activation='softmax')\n])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = model.fit(\n    train_data,\n    validation_data=val_data,\n    epochs=2\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Val Accuracy')\nplt.title(\"Vegetable Classifier Accuracy\")\nplt.legend()\nplt.show()\nmodel.save(\"vegetable_classifier_model.h5\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}